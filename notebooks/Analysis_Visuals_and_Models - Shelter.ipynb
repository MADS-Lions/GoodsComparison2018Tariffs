{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_structure, plot_supply_and_demand, regression_discontinuity_model, differences_differences, plot_for_parallel_trends \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#categories for products and services gotten by LLMs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_model_data_CAN \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed/CAN_Categorized_Products_and_Services_NEW.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\UFM\\699\\github\\GoodsComparison2018Tariffs\\notebooks\\../src\\models\\__init__.py:3\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrc_differences\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_structure, plot_supply_and_demand, regression_discontinuity_model, differences_differences, plot_for_parallel_trends \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima_model_function\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arima_model, plot_arima_results, plot_pacf_for_arima, plot_acf_pcf\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# plot_acf_for_arima, plot_ar_lag_coefficients\u001b[39;00m\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marima_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_acf_pcf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_arima_results\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_pacf_for_arima\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_structure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_supply_and_demand\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression_discontinuity_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferences_differences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_for_parallel_trends\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\UFM\\699\\github\\GoodsComparison2018Tariffs\\notebooks\\../src\\models\\arima_model_function.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpmdarima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\Python\\Python311\\Lib\\site-packages\\pmdarima\\__init__.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Stuff we want at top-level\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima, ARIMA, AutoARIMA, StepwiseContext, decompose\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf, autocorr_plot, c, pacf, plot_acf, plot_pacf, \\\n\u001b[0;32m     54\u001b[0m     tsdisplay\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\Python\\Python311\\Lib\\site-packages\\pmdarima\\arima\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapprox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\Python\\Python311\\Lib\\site-packages\\pmdarima\\arima\\approx.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# R approx function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m c, check_endog\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_callable\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\Python\\Python311\\Lib\\site-packages\\pmdarima\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Uddin\\Python\\Python311\\Lib\\site-packages\\pmdarima\\utils\\array.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m C_intgrt_vec\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_series\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_iterable\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_series\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mpmdarima\\\\utils\\\\_array.pyx:1\u001b[0m, in \u001b[0;36minit pmdarima.utils._array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import altair as alt\n",
    "sys.path.append('../src')\n",
    "from models import plot_structure, plot_supply_and_demand, regression_discontinuity_model, differences_differences, plot_for_parallel_trends \n",
    "\n",
    "#categories for products and services gotten by LLMs\n",
    "df_model_data_CAN = pd.read_csv('../data/processed/CAN_Categorized_Products_and_Services_NEW.csv')\n",
    "df_model_data_USA = pd.read_csv('../data/processed/US_Categorized_Products_and_Services_NEW.csv')\n",
    "\n",
    "#CPI data for Canada and USA to analyze Shelter inflation\n",
    "df_Canada_CPI = pd.read_csv('../data/processed/Canada_CPI_Processed_2018_2019.csv')\n",
    "df_USA_CPI = pd.read_csv('../data/processed/USA_CPI_Processed_2018_2019.csv')\n",
    "\n",
    "print(df_model_data_CAN.head())\n",
    "df_model_data_USA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#standardize and get scaled and non-scaled data for CPI data\n",
    "df_USA_CPI_melt = pd.melt(df_USA_CPI, var_name = 'Products and product groups',value_name = 'VALUE', id_vars = 'REF_DATE')\n",
    "\n",
    "df_Canada_CPI_Scaled = df_Canada_CPI.copy()\n",
    "df_Canada_CPI_NonScaled = df_Canada_CPI.copy()\n",
    "\n",
    "df_USA_CPI_Scaled = df_USA_CPI_melt.copy()\n",
    "df_USA_CPI_NonScaled = df_USA_CPI_melt.copy()\n",
    "for unique_product in df_Canada_CPI_Scaled['Products and product groups'].unique():\n",
    "    stan_scale = StandardScaler()\n",
    "    mask = df_Canada_CPI_Scaled['Products and product groups']==unique_product\n",
    "    df_Canada_CPI_Scaled.loc[mask, \"VALUE\"] = stan_scale.fit_transform(df_Canada_CPI_Scaled.loc[mask, \"VALUE\"].values[:, None]).flatten()\n",
    "for unique_product in df_USA_CPI_Scaled['Products and product groups'].unique():\n",
    "    stan_scale = StandardScaler()\n",
    "    mask = df_USA_CPI_Scaled['Products and product groups']==unique_product\n",
    "    df_USA_CPI_Scaled.loc[mask, \"VALUE\"] = stan_scale.fit_transform(df_USA_CPI_Scaled.loc[mask, \"VALUE\"].values[:, None]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canada and US datasets scaled and non-scaled and make category columns\n",
    "dict_CAN = df_model_data_CAN.drop_duplicates(subset=['Product_Service']).set_index('Product_Service')['Category'].to_dict()\n",
    "dict_USA = df_model_data_USA.drop_duplicates(subset=['Product_Service']).set_index('Product_Service')['Category'].to_dict()\n",
    "\n",
    "df_Canada_CPI_Scaled['Category'] = df_Canada_CPI['Products and product groups'].map(dict_CAN)\n",
    "df_Canada_CPI_NonScaled['Category'] = df_Canada_CPI['Products and product groups'].map(dict_CAN)\n",
    "df_USA_CPI_Scaled['Category'] = df_USA_CPI_Scaled['Products and product groups'].map(dict_USA)\n",
    "df_USA_CPI_NonScaled['Category'] = df_USA_CPI_NonScaled['Products and product groups'].map(dict_USA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make groupby dataframe get median of each category\n",
    "df_Canada_CPI_Cat = df_Canada_CPI_Scaled.copy().drop(columns = ['Products and product groups'])\n",
    "df_Canada_CPI_groupby = df_Canada_CPI_Cat.groupby(['REF_DATE', 'Category']).median().reset_index()\n",
    "\n",
    "df_Canada_CPI_Cat_NonScaled = df_Canada_CPI_NonScaled.copy().drop(columns = ['Products and product groups'])\n",
    "df_Canada_CPI_groupby_NonScaled = df_Canada_CPI_Cat_NonScaled.groupby(['REF_DATE', 'Category']).median().reset_index()\n",
    "\n",
    "df_USA_CPI_Cat = df_USA_CPI_Scaled.copy().drop(columns = ['Products and product groups'])\n",
    "df_USA_CPI_groupby = df_USA_CPI_Cat.groupby(['REF_DATE', 'Category']).median().reset_index()\n",
    "\n",
    "df_USA_CPI_Cat_NonScaled = df_USA_CPI_NonScaled.copy().drop(columns = ['Products and product groups'])\n",
    "df_USA_CPI_groupby_NonScaled = df_USA_CPI_Cat_NonScaled.groupby(['REF_DATE', 'Category']).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at all potential categories\n",
    "for column in df_Canada_CPI_groupby['Category'].unique():\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at plot Shelter which was more impacted and compare to Education & Reading which was less impacted by tariffs\n",
    "plot_for_parallel_trends(df_Canada_CPI_groupby, '2018-01-01', '2018-11-01', 'Shelter', 'Education & Reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at china tariffs for differences in differences to get a better idea for one month\n",
    "differences_differences(df_Canada_CPI_groupby, 'Shelter', 'Education & Reading', '2018-07-01', '2018-09-01', '2018-08-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems like the groupby shows some interaction \n",
    "#let us investigate into specific Shelter categories to see which categories may have been impacted by the tariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shelter_items = df_Canada_CPI_NonScaled[(df_Canada_CPI_NonScaled['Category'] == 'Shelter')]['Products and product groups'].unique()\n",
    "\n",
    "shelter_dataframe = df_Canada_CPI_NonScaled[(df_Canada_CPI_NonScaled['Category'] == 'Shelter') | (df_Canada_CPI_NonScaled['Category'] == 'Education & Reading')]\n",
    "\n",
    "\n",
    "dict_shelter = shelter_categories = {\n",
    "    \"Homeowners' home and mortgage insurance\": 'Owned accommodation',\n",
    "    \"Homeowners' maintenance and repairs\": 'Owned accommodation',\n",
    "    \"Homeowners' replacement cost\": 'Owned accommodation',\n",
    "    \"Mortgage interest cost\": 'Owned accommodation',\n",
    "    \"Other owned accommodation expenses\": 'Owned accommodation',\n",
    "    \"Property taxes and other special charges\": 'Owned accommodation',\n",
    "    \"Rent\": 'Rented accommodation',\n",
    "    \"Tenants' insurance premiums\": 'Rented accommodation',\n",
    "    \"Tenants' maintenance, repairs and other expenses\": 'Rented accommodation',\n",
    "    \"Electricity\": 'Water, fuel and electricity',\n",
    "    \"Fuel oil and other fuels\": 'Water, fuel and electricity',\n",
    "    \"Natural gas\": 'Water, fuel and electricity',\n",
    "    \"Water\": 'Water, fuel and electricity',\n",
    "    'Books and reading material (excluding textbooks)':'Books, Magazines & Newspaper',\n",
    "    'Education':'Education',\t\t\t\t\t\n",
    "    'Education and reading':'Education',\t\t\t\t\n",
    "    'Magazines and periodicals':'Books, Magazines & Newspaper',\t\t\t\n",
    "    'Newspapers':'Books, Magazines & Newspaper',\t\t\t\t\t\n",
    "    'Reading material (excluding textbooks)':'Books, Magazines & Newspaper',\t\t\n",
    "    'Recreation, education and reading':'Education',\t\t\n",
    "    'School textbooks and supplies':'Books, Magazines & Newspaper',\t\t\t\n",
    "    'Tuition fees':'Education'\n",
    "}\n",
    "\n",
    "dict_shelter_US= {\n",
    "    'Owned accommodation': [\n",
    "        'Fuels and utilities', 'Household energy', 'Housing', 'Housing at school, excluding board',\n",
    "        \"Owners' equivalent rent of primary residence\", \"Owners' equivalent rent of residences\"\n",
    "    ],\n",
    "    'Rented accommodation': [\n",
    "        'Rent of primary residence', 'Rent of shelter', 'Services less rent of shelter'\n",
    "    ],\n",
    "    'Water, fuel and electricity': [\n",
    "        'Utility (piped) gas service', 'Water and sewer and trash collection services','Water and sewerage maintenance'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "US_shelter_dataset = df_USA_CPI_NonScaled[(df_USA_CPI_NonScaled['Category'] == 'Shelter') | (df_USA_CPI_NonScaled['Category'] == 'Education & Reading')]\n",
    "\n",
    "print(US_shelter_dataset['Products and product groups'].unique())\n",
    "\n",
    "US_shelter_dataset['Category'] = US_shelter_dataset['Category'].map(dict_shelter_US)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make grocery categories within the grocery category dataframe\n",
    "shelter_dataframe['Category'] = shelter_dataframe['Products and product groups'].map(dict_shelter)\n",
    "\n",
    "shelter_dataframe.drop(columns = ['Products and product groups'], inplace=True)\n",
    "print(shelter_dataframe['Category'].unique())\n",
    "grocery_dataframe_groupby = shelter_dataframe.groupby(['REF_DATE', 'Category']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Canada_RC_shelter_first_tariff, _, _, _ = regression_discontinuity_model(df_Canada_CPI_groupby, 'Shelter', '2017-10-01', '2018-06-01', '2018-03-01', '2018-04-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_Canada_RC_shelter_first_tariff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Canada_RC_shelter_second_tariff, _, _, _ = regression_discontinuity_model(df_Canada_CPI_groupby, 'Shelter', '2018-05-01', '2018-12-01', '2018-07-01', '2018-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Canada_RC_shelter_second_tariff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tariff_vs_second_tariff, _, _, _ = regression_discontinuity_model(df_Canada_CPI_groupby, 'Shelter', '2017-10-01', '2018-12-01', '2018-05-01')\n",
    "\n",
    "first_tariff_vs_second_tariff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it seems like american tariffs had little immediate impact on Canadian shelter when looking at manufacturing even the only month affected was the China tariffs in August as mentioned supply was still high - it is hard to disentangle the impact of the tariffs and the news so perhaps we should look for a more long term approach to gain more insight to what happened with groceries\n",
    "\n",
    "\n",
    "Canada_parallel_trends_shelter = plot_for_parallel_trends(df_Canada_CPI_groupby, '2017-01-01', '2019-10-01', 'Shelter', 'Education & Reading')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is hard to quantify the impact of shelter based on specific tariffs due to the serial correlation of tariffs but looking from the start of the breakdown in China talks to the Chinese hike tax we will look at RD between these periods and see if we can draw conclusions\n",
    "#there does seem to be greater variance from the start of the Intellectual Property Trials to the Chinese hike in tariffs that started propagating like a wave with each tariff with minimal activity following the results of the IP investigation - let us investigate further\n",
    "model_shelter_longterm_IP, _, _, _ = regression_discontinuity_model(df_Canada_CPI_groupby, 'Shelter', '2017-01-01', '2018-04-01', '2017-08-01', heteroskedasticity = 'nonrobust')\n",
    "\n",
    "model_shelter_longterm_IP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next lets compare with RD the tariff / IP trails period to the Chinese hike in tariffs\n",
    "model_groceries_longterm_recovery, _, _, _ = regression_discontinuity_model(df_Canada_CPI_groupby, 'Shelter', '2018-02-01', '2019-05-01', '2018-11-01', '2019-01-01')\n",
    "\n",
    "print(model_groceries_longterm_recovery.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us look at what happened in American shelter due to the tariffs and compare the effect of the tariffs on shelter for US tariffs vs Canadian tariffs\n",
    "#they appear to have a similar effect on American goods\n",
    "\n",
    "plot_structure(df_USA_CPI_groupby, 'Shelter', '2017-01-01', '2020-02-01')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It appears that the American shelter dataset follows the Canadian with waves except the breakdown in china talks led to a decrease in inflation for Canadian shelter but an increase for American shelter\n",
    "# We will look at the IP investigation later but it appears trumps tariffs on Canadian goods had only a small impact on American shelter but the combination of Canadian announcement of tariffs, canadian tariffs and chinese tariffs on American exported goods may have had a larger impact, let us investigate further\n",
    "model_USA_RC_shelter_cutoff_first_tariff, _, _, _ = regression_discontinuity_model(df_USA_CPI_groupby, 'Shelter', '2017-10-01', '2018-06-01', '2018-03-01', '2018-04-01')\n",
    "\n",
    "print(model_USA_RC_shelter_cutoff_first_tariff.summary())\n",
    "model_USA_RC_shelter_cutoff_second_tariff, _, _, _= regression_discontinuity_model(df_USA_CPI_groupby, 'Shelter', '2018-05-01', '2018-12-01', '2018-07-01', '2018-10-01')\n",
    "\n",
    "print(model_USA_RC_shelter_cutoff_second_tariff.summary())\n",
    "\n",
    "model_longterm_impact_shelter, _, _, _ = regression_discontinuity_model(df_USA_CPI_groupby, 'Shelter', '2017-10-01', '2019-12-01', '2018-02-01', '2018-04-01')\n",
    "\n",
    "print(model_longterm_impact_shelter.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_USA_CPI_groupby['Category'].unique())\n",
    "USA_parallel_trends_shelter = plot_for_parallel_trends(df_USA_CPI_groupby, '2017-01-01', '2019-12-01', 'Shelter', 'Education & Reading', category_3 = None)\n",
    "\n",
    "USA_parallel_trends_shelter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_differences(df_USA_CPI_Scaled, 'Shelter', 'Education & Reading', '2018-03-01', '2018-05-01', '2018-04-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_differences(df_USA_CPI_groupby, 'Shelter', 'Education & Reading', '2018-03-01', '2018-05-01', '2018-04-01')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
